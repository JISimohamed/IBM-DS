{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2db9daaf-a2c8-4da2-90a7-ed625af516ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13f8e1a5-2a7b-45c9-be3d-2793685e7304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cellular system environment (simplified for the example)\n",
    "class CellularEnv(gym.Env):\n",
    "    def __init__(self, num_users=10, num_rb=5):\n",
    "        super(CellularEnv, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_rb = num_rb\n",
    "        \n",
    "        # Define action and observation space\n",
    "        # Action space: Allocation matrix (num_users x num_rb)\n",
    "        self.action_space = gym.spaces.Box(low=0, high=1, shape=(self.num_users, self.num_rb), dtype=np.float32)\n",
    "        \n",
    "        # Observation space: Could be rates for each user, channel gains, etc.\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=np.inf, shape=(self.num_users, ), dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        # Initialize or reset the state (e.g., initial channel conditions or rates)\n",
    "        self.state = np.random.rand(self.num_users)\n",
    "        return self.state\n",
    "    \n",
    "    def step(self, action):\n",
    "        # Apply the action (resource allocation)\n",
    "        allocation_matrix = action\n",
    "        \n",
    "        # Simulate the environment dynamics\n",
    "        # Here, we calculate user rates based on resource allocation (simplified)\n",
    "        rates = np.dot(allocation_matrix, np.random.rand(self.num_rb))\n",
    "        \n",
    "        # Reward: we can define it as the sum of the user rates or based on a custom function\n",
    "        reward = np.sum(rates)\n",
    "        # Observation: return new rates\n",
    "        obs = rates\n",
    "        \n",
    "        # Done flag (usually when episode is over, but we can make it continuous)\n",
    "        done = False\n",
    "        \n",
    "        return obs, reward, done, {}\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275435f7-1b53-4abf-b27e-68918882e3ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\anaconda3\\envs\\chatbot_env\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1012 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 2    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 689         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024505755 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | -7.9e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.4e+03     |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.0474     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.57e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 665         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 9           |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018388914 |\n",
      "|    clip_fraction        | 0.239       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71         |\n",
      "|    explained_variance   | -0.00189    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.08e+03    |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0373     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.7e+04     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 673         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020099245 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | -0.000257   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 7.78e+03    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0414     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.68e+04    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 668         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018802773 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -71.1       |\n",
      "|    explained_variance   | -0.000733   |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 8.19e+03    |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0388     |\n",
      "|    std                  | 1           |\n",
      "|    value_loss           | 1.75e+04    |\n",
      "-----------------------------------------\n",
      "Step 1: Action: [[[1.         0.5760262  0.         0.         0.        ]\n",
      "  [0.         0.         0.         1.         0.9298819 ]\n",
      "  [0.         0.         0.76523143 0.9409639  0.42960906]\n",
      "  [0.         0.         0.25849038 0.         1.        ]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.         1.         0.         1.         0.        ]\n",
      "  [0.82698315 0.2834506  0.         0.         0.7073761 ]\n",
      "  [0.         0.38817722 0.         0.28979596 0.8288889 ]\n",
      "  [0.         0.7834526  0.         1.         0.        ]\n",
      "  [0.         0.         0.         0.46851406 1.        ]]], Reward: [10.871796]\n",
      "Step 2: Action: [[[0.24475056 0.         0.21621522 0.4708489  0.        ]\n",
      "  [0.         1.         0.36234543 0.         0.82459253]\n",
      "  [0.64977443 0.70092666 0.         0.         0.        ]\n",
      "  [0.         0.         0.7463859  1.         0.35108244]\n",
      "  [0.         0.7698271  0.         0.5430628  0.18435533]\n",
      "  [0.64380467 0.         0.         0.         0.        ]\n",
      "  [1.         0.         1.         0.7923433  0.        ]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.         1.         0.         0.         0.10719115]\n",
      "  [1.         0.75652707 0.         0.         0.        ]]], Reward: [7.39032]\n",
      "Step 3: Action: [[[0.         0.         0.90267205 0.         0.        ]\n",
      "  [0.99418813 0.08129606 0.45171604 1.         0.57611513]\n",
      "  [0.         0.         0.5380894  0.         1.        ]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.         0.         0.         1.         0.        ]\n",
      "  [0.         0.         0.         0.4546099  0.5732162 ]\n",
      "  [0.2844869  0.         0.2936133  0.         0.        ]\n",
      "  [0.         1.         0.15811332 0.08279873 0.61733663]\n",
      "  [1.         0.         0.79091984 0.0474708  0.09387596]\n",
      "  [1.         0.8212109  0.50914335 0.12490906 0.        ]]], Reward: [6.6109085]\n",
      "Step 4: Action: [[[0.         0.         0.         0.01174235 0.        ]\n",
      "  [1.         1.         0.10895775 0.29275578 0.        ]\n",
      "  [0.6155549  1.         0.12014466 0.         0.        ]\n",
      "  [0.         0.0648119  0.7095358  0.         0.93886244]\n",
      "  [1.         0.         0.5953202  0.684446   0.6649482 ]\n",
      "  [0.33683997 0.         0.         0.         0.        ]\n",
      "  [1.         0.0135431  0.5907354  0.         0.274933  ]\n",
      "  [0.7873556  0.         1.         0.         0.        ]\n",
      "  [0.         0.28341895 0.5510049  0.         0.39763984]\n",
      "  [0.         0.42008328 0.         0.         0.        ]]], Reward: [8.607521]\n",
      "Step 5: Action: [[[1.         1.         1.         0.         0.        ]\n",
      "  [0.         0.3389496  0.42534363 0.         0.77389115]\n",
      "  [0.         0.         0.         1.         0.        ]\n",
      "  [0.4766453  0.         0.         0.         0.36587393]\n",
      "  [0.9636226  0.         1.         0.06876928 0.        ]\n",
      "  [0.         1.         0.         0.         0.        ]\n",
      "  [0.94231486 1.         0.         0.11798586 0.        ]\n",
      "  [0.         0.62956166 0.         0.         0.        ]\n",
      "  [1.         0.30440855 1.         0.         0.        ]\n",
      "  [0.79091424 0.11635347 1.         0.         1.        ]]], Reward: [6.2624764]\n",
      "Step 6: Action: [[[0.8972791  0.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.36514443 0.        ]\n",
      "  [0.         1.         0.5192816  0.90847725 0.04505735]\n",
      "  [1.         0.15852182 0.95302516 0.13677716 0.        ]\n",
      "  [0.         0.01343993 0.5858212  0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         1.         0.9930196  0.18218563 0.        ]\n",
      "  [0.         0.         0.4527727  0.86363655 0.28815812]\n",
      "  [0.         0.         1.         0.66615355 0.        ]\n",
      "  [0.07655244 0.96490264 0.         1.         0.7133244 ]]], Reward: [8.787161]\n",
      "Step 7: Action: [[[0.05152053 1.         0.         0.         0.        ]\n",
      "  [0.07057028 0.14591916 1.         0.         0.        ]\n",
      "  [0.         1.         0.26406455 0.50005394 0.44322148]\n",
      "  [0.         0.808593   1.         0.         0.        ]\n",
      "  [1.         0.         0.         0.90365064 0.5757909 ]\n",
      "  [0.         0.60165083 0.         0.         0.73782057]\n",
      "  [0.         0.41871935 0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.         0.4728949 ]\n",
      "  [0.4741183  0.         0.         1.         0.8475226 ]\n",
      "  [0.         0.         0.         0.         0.        ]]], Reward: [8.353114]\n",
      "Step 8: Action: [[[0.86558574 0.         0.         0.         0.5039496 ]\n",
      "  [1.         0.         0.17330594 1.         0.        ]\n",
      "  [0.41541868 1.         0.         0.3664137  0.        ]\n",
      "  [1.         0.         0.13987356 1.         1.        ]\n",
      "  [1.         0.         0.         0.         0.8157596 ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.87276053 0.         0.         0.55966324]\n",
      "  [0.6704033  0.2754298  0.75873005 0.00788806 0.        ]\n",
      "  [0.44158053 0.         0.38483927 0.         0.9571503 ]\n",
      "  [1.         0.4292485  0.29338852 0.43725258 0.23614115]]], Reward: [12.742771]\n",
      "Step 9: Action: [[[0.         1.         1.         1.         1.        ]\n",
      "  [0.         0.         0.8552723  0.         0.        ]\n",
      "  [1.         0.582952   0.22310112 0.7956899  0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.08112423 0.88462913 0.         0.        ]\n",
      "  [0.         0.74121517 0.4706482  0.37024522 1.        ]\n",
      "  [0.66356784 0.04400842 0.         0.8373465  0.24422175]\n",
      "  [0.         0.         0.         0.03641722 0.4376139 ]\n",
      "  [0.09610459 0.         0.         0.         0.        ]\n",
      "  [0.10364205 0.         0.         0.8608792  1.        ]]], Reward: [6.6278667]\n",
      "Step 10: Action: [[[1.         0.         0.         0.         0.        ]\n",
      "  [0.         0.27730772 0.7857181  0.82217824 0.        ]\n",
      "  [0.53574544 0.58566254 1.         0.         0.        ]\n",
      "  [0.         0.         0.         0.34136575 0.        ]\n",
      "  [0.         0.15793951 0.         0.4706337  0.        ]\n",
      "  [0.         0.05955201 0.         0.         0.05533912]\n",
      "  [0.         1.         1.         1.         0.        ]\n",
      "  [0.         0.         0.11788237 0.236632   0.8810373 ]\n",
      "  [0.         1.         0.16234802 0.78295857 1.        ]\n",
      "  [0.41936424 0.0449673  1.         0.89374536 0.        ]]], Reward: [6.415708]\n",
      "Step 11: Action: [[[0.90127295 0.         0.         0.99201196 0.        ]\n",
      "  [1.         0.51485634 0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.4674091  0.47827786 0.12003054 0.         0.5170649 ]\n",
      "  [0.         0.         1.         0.         0.909196  ]\n",
      "  [0.         0.         0.17903155 1.         0.16159801]\n",
      "  [0.         0.         0.         0.814131   0.05663036]\n",
      "  [1.         1.         0.         0.         0.07350586]\n",
      "  [0.7913829  1.         1.         1.         0.        ]\n",
      "  [0.         1.         0.         0.7184114  1.        ]]], Reward: [9.102839]\n",
      "Step 12: Action: [[[0.22499347 1.         1.         0.32261816 0.        ]\n",
      "  [0.         0.5729217  0.86247134 0.         0.        ]\n",
      "  [0.         1.         0.         0.23403253 0.        ]\n",
      "  [0.         1.         0.         0.         0.1332571 ]\n",
      "  [0.         0.08423907 0.38187084 0.         0.        ]\n",
      "  [0.         0.         0.8203637  0.         0.        ]\n",
      "  [1.         0.         0.         0.         0.        ]\n",
      "  [0.77411145 0.80324984 0.20269248 0.         0.        ]\n",
      "  [1.         0.41209316 0.         0.         0.20819089]\n",
      "  [0.         1.         0.         0.         0.        ]]], Reward: [8.961031]\n",
      "Step 13: Action: [[[1.         0.         0.         0.         0.        ]\n",
      "  [0.         1.         0.         0.38507488 0.        ]\n",
      "  [0.         0.         0.         0.         0.9821409 ]\n",
      "  [0.57220393 0.31765223 0.8313891  0.57762015 1.        ]\n",
      "  [0.         0.9393444  0.         0.         0.8098021 ]\n",
      "  [0.         0.33352572 0.8465181  0.         0.        ]\n",
      "  [0.60023016 0.4515776  1.         0.         0.30060652]\n",
      "  [0.         1.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.4322307  0.92338204 1.         1.         0.5084783 ]]], Reward: [9.579087]\n",
      "Step 14: Action: [[[0.5738142  1.         0.         0.         0.01242462]\n",
      "  [0.         0.14227441 0.         0.35111064 0.42796677]\n",
      "  [0.01856907 0.         0.         0.         0.        ]\n",
      "  [1.         0.08328196 0.         1.         0.4406036 ]\n",
      "  [0.9788297  0.         1.         0.         0.        ]\n",
      "  [0.6238961  0.928257   0.83904904 0.         1.        ]\n",
      "  [0.         0.         0.7906765  0.35524645 1.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [1.         0.16060458 0.722484   0.04980993 0.09649313]\n",
      "  [0.35292035 0.9614289  0.         0.         0.23560828]]], Reward: [9.493251]\n",
      "Step 15: Action: [[[0.         0.         1.         0.         0.        ]\n",
      "  [1.         0.09085919 0.         0.         0.        ]\n",
      "  [0.         0.         0.4906322  0.8995719  1.        ]\n",
      "  [0.         0.6974555  0.9381064  1.         0.        ]\n",
      "  [0.41605508 0.         0.19866453 0.5743148  0.        ]\n",
      "  [1.         0.         0.         0.43932086 0.9202678 ]\n",
      "  [1.         0.6948568  0.9712226  0.00550127 1.        ]\n",
      "  [0.         0.         0.         0.         0.12707971]\n",
      "  [0.         0.         0.09713827 0.63483655 0.7790522 ]\n",
      "  [0.529593   0.2427325  1.         0.30924895 0.        ]]], Reward: [12.044355]\n",
      "Step 16: Action: [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 2.9625502e-01 0.0000000e+00]\n",
      "  [0.0000000e+00 4.6489295e-04 7.8742516e-01 0.0000000e+00 0.0000000e+00]\n",
      "  [8.6558259e-01 0.0000000e+00 7.5801596e-02 1.0000000e+00 0.0000000e+00]\n",
      "  [8.2315654e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.1175845e-01]\n",
      "  [0.0000000e+00 0.0000000e+00 1.0000000e+00 8.9248702e-02 0.0000000e+00]\n",
      "  [1.2502256e-01 1.4279623e-01 7.5950909e-01 0.0000000e+00 0.0000000e+00]\n",
      "  [1.0000000e+00 0.0000000e+00 5.5070561e-01 1.2366220e-02 1.0000000e+00]\n",
      "  [2.5161275e-01 0.0000000e+00 0.0000000e+00 4.9564418e-01 4.8778364e-01]\n",
      "  [7.1576166e-01 1.0000000e+00 4.9622189e-02 0.0000000e+00 0.0000000e+00]\n",
      "  [1.5475690e-01 6.2711698e-01 0.0000000e+00 7.5863354e-02 9.8870194e-01]]], Reward: [5.671999]\n",
      "Step 17: Action: [[[0.9617138  0.6016029  0.40016362 0.7901327  0.        ]\n",
      "  [0.         0.5312999  0.         1.         0.        ]\n",
      "  [0.26153448 1.         1.         1.         0.        ]\n",
      "  [0.336344   0.4089645  1.         0.7202168  0.3678488 ]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.         0.43526265 0.2289654  0.07679637 0.        ]\n",
      "  [1.         0.4511008  0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.         1.        ]\n",
      "  [0.20181957 0.         0.8318626  0.         1.        ]\n",
      "  [0.         1.         0.         0.         0.        ]]], Reward: [8.044209]\n",
      "Step 18: Action: [[[1.         1.         0.680733   0.37375978 0.8207579 ]\n",
      "  [0.97592765 0.         0.57809037 0.25415832 0.        ]\n",
      "  [0.         0.         1.         1.         0.01904881]\n",
      "  [0.         0.         0.         0.22381638 0.        ]\n",
      "  [0.         0.7569017  0.0730668  0.         0.        ]\n",
      "  [1.         0.         0.22515082 0.         0.36218107]\n",
      "  [1.         0.         0.46154648 0.9305546  0.        ]\n",
      "  [0.12366434 0.         0.25284085 0.         0.        ]\n",
      "  [0.         0.85991335 0.         1.         0.78838104]\n",
      "  [0.09591927 1.         0.         0.6033329  1.        ]]], Reward: [7.9812927]\n",
      "Step 19: Action: [[[0.         0.83387464 0.         0.5081864  0.5835058 ]\n",
      "  [0.         0.6502591  0.42352766 0.         0.        ]\n",
      "  [0.5827805  0.29893845 0.         0.4342701  1.        ]\n",
      "  [0.1135087  0.85250986 0.16276607 0.         0.00707971]\n",
      "  [0.         0.         0.         0.         0.9823203 ]\n",
      "  [0.         0.         0.         0.91076463 0.        ]\n",
      "  [1.         0.         0.         0.36873466 0.        ]\n",
      "  [0.61035836 0.05024467 0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.7833848  1.         0.         0.         0.        ]]], Reward: [2.9898088]\n",
      "Step 20: Action: [[[0.0000000e+00 1.0000000e+00 3.8892597e-01 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 5.4594874e-04 0.0000000e+00 6.3018745e-01 1.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 5.3887135e-01]\n",
      "  [0.0000000e+00 1.0000000e+00 4.8227805e-01 7.8399107e-04 7.6720732e-01]\n",
      "  [0.0000000e+00 7.1210366e-01 6.0010839e-01 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 5.1279175e-01 1.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      "  [5.1428694e-01 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      "  [0.0000000e+00 6.4763981e-01 8.6905354e-01 5.5110383e-01 1.0000000e+00]\n",
      "  [6.7733556e-01 4.2584431e-01 0.0000000e+00 5.0313365e-01 1.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 3.3738577e-01 0.0000000e+00 0.0000000e+00]]], Reward: [2.8725293]\n",
      "Step 21: Action: [[[0.69513595 1.         0.         0.         0.        ]\n",
      "  [1.         0.6287788  0.         0.         0.        ]\n",
      "  [0.84519523 0.         0.         0.         0.        ]\n",
      "  [0.5232377  0.         0.28109956 0.         0.3241401 ]\n",
      "  [0.07350422 1.         0.         0.         0.        ]\n",
      "  [0.6637498  1.         0.         0.98293865 0.        ]\n",
      "  [0.         0.         0.         0.         0.67153305]\n",
      "  [0.3966982  0.         0.         1.         0.23076066]\n",
      "  [0.         1.         0.         0.36729264 0.        ]\n",
      "  [0.60477024 0.29766792 0.         1.         0.40495497]]], Reward: [11.391816]\n",
      "Step 22: Action: [[[1.         0.7729167  0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.8760244  1.        ]\n",
      "  [0.46665797 0.         0.91056097 1.         1.        ]\n",
      "  [1.         0.         0.         1.         0.1289741 ]\n",
      "  [1.         1.         0.37806076 1.         0.25656188]\n",
      "  [0.         0.5772953  0.         0.27147302 1.        ]\n",
      "  [0.         0.         0.         1.         0.        ]\n",
      "  [0.80748105 0.20078683 0.70219153 1.         0.        ]\n",
      "  [0.50954854 0.4520461  0.         0.         0.        ]\n",
      "  [0.3740936  0.         0.59384286 0.20638448 0.9168044 ]]], Reward: [8.324326]\n",
      "Step 23: Action: [[[0.         0.         0.         0.09253223 0.        ]\n",
      "  [1.         0.         0.03420331 0.         1.        ]\n",
      "  [1.         0.05215737 0.7646243  1.         0.        ]\n",
      "  [0.19129194 0.787446   0.51166093 0.         0.14061594]\n",
      "  [0.01822409 0.         0.         1.         0.        ]\n",
      "  [0.         0.34216797 0.         0.         0.        ]\n",
      "  [0.         0.         0.47735286 0.02580206 0.02813993]\n",
      "  [0.38316536 1.         0.         0.365487   1.        ]\n",
      "  [0.         1.         1.         0.8886162  0.        ]\n",
      "  [0.01360051 0.         0.         0.9350867  1.        ]]], Reward: [3.4615016]\n",
      "Step 24: Action: [[[0.05099223 0.         1.         0.8725464  1.        ]\n",
      "  [1.         0.82999784 0.26586747 0.06086385 1.        ]\n",
      "  [0.35619092 0.8955158  1.         1.         0.70670986]\n",
      "  [0.         0.14790498 1.         0.9737872  0.78088504]\n",
      "  [0.         0.35512006 0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.         0.22222115]\n",
      "  [0.         1.         1.         1.         0.        ]\n",
      "  [0.6166377  0.         0.         0.52581465 0.8663203 ]\n",
      "  [0.5245923  1.         1.         0.8821289  1.        ]\n",
      "  [0.         1.         0.8344391  0.650658   1.        ]]], Reward: [16.86673]\n",
      "Step 25: Action: [[[1.         1.         0.97495943 1.         1.        ]\n",
      "  [0.4112991  0.         1.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.3273544  0.         0.7760808  0.         0.        ]\n",
      "  [0.6260506  0.         1.         0.         1.        ]\n",
      "  [0.         0.         0.11663893 0.493439   1.        ]\n",
      "  [0.95036286 0.         0.83310956 0.         0.        ]\n",
      "  [0.         0.44586158 1.         0.         0.9413329 ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.        ]]], Reward: [9.011851]\n",
      "Step 26: Action: [[[0.17781632 0.6240814  0.         0.         0.        ]\n",
      "  [0.         1.         0.9260959  0.         0.        ]\n",
      "  [1.         0.59852564 0.8578849  1.         1.        ]\n",
      "  [0.296279   0.53088945 0.45001468 0.         0.        ]\n",
      "  [0.34164983 0.         0.56623125 0.9571925  0.        ]\n",
      "  [0.         0.         0.         0.3320353  0.64875966]\n",
      "  [0.         0.         0.         0.         0.7963178 ]\n",
      "  [0.         0.6409005  0.         1.         0.        ]\n",
      "  [0.         0.5032145  0.42877388 0.         0.36981112]\n",
      "  [0.         1.         1.         0.         0.        ]]], Reward: [12.794567]\n",
      "Step 27: Action: [[[1.         0.92175347 0.27620506 1.         0.15317255]\n",
      "  [0.         0.45212013 0.36112213 0.29155606 0.69320613]\n",
      "  [0.09302058 0.         0.         0.         0.00380418]\n",
      "  [0.         0.         0.1771354  0.         1.        ]\n",
      "  [1.         0.05897371 0.         1.         0.        ]\n",
      "  [0.76835877 0.97020555 1.         0.         0.        ]\n",
      "  [0.         0.         0.         0.7633419  0.        ]\n",
      "  [0.21155927 0.4451421  1.         0.5556486  0.11453086]\n",
      "  [0.         0.         0.02860834 1.         0.15152006]\n",
      "  [0.981694   1.         0.         0.         0.        ]]], Reward: [8.770471]\n",
      "Step 28: Action: [[[0.24021271 0.4033552  0.49663106 0.         0.8937787 ]\n",
      "  [0.82935286 0.         0.         0.         1.        ]\n",
      "  [1.         0.         0.85081464 0.03692837 0.        ]\n",
      "  [0.         0.5616076  0.07185894 0.         0.06311864]\n",
      "  [0.5125556  0.         0.         0.9511988  0.06981134]\n",
      "  [1.         0.7901121  0.         0.13065399 0.        ]\n",
      "  [0.         0.         0.         0.         0.52379346]\n",
      "  [0.8178868  0.         0.         0.65136015 0.        ]\n",
      "  [0.         0.         0.79534906 0.9896267  0.        ]\n",
      "  [0.         0.         1.         0.         0.        ]]], Reward: [7.1738725]\n",
      "Step 29: Action: [[[0.         0.539684   0.         1.         0.        ]\n",
      "  [0.5254384  0.         1.         0.         0.85133165]\n",
      "  [0.17001235 0.         0.22503774 1.         1.        ]\n",
      "  [0.         0.4362177  0.         0.         0.        ]\n",
      "  [0.         0.         1.         1.         0.        ]\n",
      "  [0.11904942 0.         0.         0.         0.5880929 ]\n",
      "  [1.         0.         0.33933645 0.         0.        ]\n",
      "  [0.         0.22652975 0.35854146 0.         0.        ]\n",
      "  [0.         1.         0.         0.         1.        ]\n",
      "  [1.         0.09330546 0.         0.         0.        ]]], Reward: [8.948187]\n",
      "Step 30: Action: [[[0.5555564  0.86868984 0.12187763 1.         0.        ]\n",
      "  [0.30720782 0.         0.         1.         0.        ]\n",
      "  [0.         0.         0.02075364 0.         1.        ]\n",
      "  [0.86556166 0.39209116 0.         0.6884309  0.7034989 ]\n",
      "  [0.         0.3463136  0.         0.         0.43016022]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.28031564 1.         0.09336129 1.         0.        ]\n",
      "  [0.7100971  0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.01562074 0.         0.46518955]\n",
      "  [1.         0.0931113  0.5297108  1.         0.        ]]], Reward: [7.4982257]\n",
      "Step 31: Action: [[[1.         0.         1.         0.         0.        ]\n",
      "  [0.13758174 0.         0.         0.         0.07421143]\n",
      "  [0.5496281  0.         0.9581462  0.         0.65365416]\n",
      "  [0.16411953 0.3668378  0.768082   1.         0.        ]\n",
      "  [0.         0.         0.85303235 0.59873956 0.00155508]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.08015352 0.1842189  1.         0.         0.        ]\n",
      "  [0.         1.         0.24019347 0.         0.        ]\n",
      "  [0.         0.         0.         0.59427214 0.00422741]\n",
      "  [0.         0.53201854 0.31442684 0.1249948  0.        ]]], Reward: [4.2453713]\n",
      "Step 32: Action: [[[0.         0.         0.         1.         0.        ]\n",
      "  [0.5057262  0.         1.         0.45678222 0.        ]\n",
      "  [0.         0.9674345  0.97761965 0.04491786 0.25890368]\n",
      "  [0.726294   1.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.30987296 0.7935114 ]\n",
      "  [0.         0.47999948 0.74357194 0.         0.04263693]\n",
      "  [0.96550125 0.         0.725354   0.         0.5265672 ]\n",
      "  [0.19409774 0.         0.00784355 0.         0.        ]\n",
      "  [0.         0.         0.37621823 0.         0.35978425]\n",
      "  [0.         0.         0.         0.         1.        ]]], Reward: [8.9373255]\n",
      "Step 33: Action: [[[0.40369987 0.         1.         0.9740506  0.        ]\n",
      "  [0.         0.         0.         0.38071406 1.        ]\n",
      "  [0.4318119  0.7768574  0.         0.         0.90130866]\n",
      "  [0.29298982 0.         1.         1.         1.        ]\n",
      "  [0.         1.         0.8366583  0.9088189  0.        ]\n",
      "  [0.         0.20015723 0.         0.         0.        ]\n",
      "  [0.85939956 0.6063223  0.         1.         0.2765522 ]\n",
      "  [0.         1.         0.         0.         0.570561  ]\n",
      "  [0.00323411 0.56689745 0.7420591  0.         0.6515567 ]\n",
      "  [0.         0.         0.         0.         0.        ]]], Reward: [8.843153]\n",
      "Step 34: Action: [[[0.         0.         0.5102063  1.         1.        ]\n",
      "  [0.9623059  0.10278556 0.         0.         0.46663645]\n",
      "  [0.6956599  0.         0.346802   1.         0.        ]\n",
      "  [0.         0.         0.         0.         0.25190058]\n",
      "  [0.44615644 0.         1.         0.6213666  0.        ]\n",
      "  [0.         0.12406395 0.54139334 0.12498049 0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.32351893 0.         0.3440155  0.        ]\n",
      "  [0.         0.7880364  1.         0.5046632  0.3510521 ]\n",
      "  [0.         0.8264685  1.         0.49564013 0.        ]]], Reward: [7.1386275]\n",
      "Step 35: Action: [[[0.05789153 1.         0.         1.         0.        ]\n",
      "  [0.         0.         0.         0.         0.70932835]\n",
      "  [0.         0.         0.         1.         0.        ]\n",
      "  [0.         0.         0.         0.8020186  1.        ]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [1.         0.60258347 0.         0.86879367 0.3316969 ]\n",
      "  [0.05980605 0.         1.         0.         0.77337855]\n",
      "  [0.3817311  1.         0.         0.         0.        ]\n",
      "  [0.         0.5964489  0.9730225  0.31550637 0.        ]\n",
      "  [0.6595996  0.         0.         0.         0.        ]]], Reward: [8.585525]\n",
      "Step 36: Action: [[[0.         1.         0.         1.         0.8002056 ]\n",
      "  [0.8627048  0.         1.         0.         0.        ]\n",
      "  [0.3655293  0.         0.         0.3425282  0.8405077 ]\n",
      "  [0.         1.         0.         0.47414902 1.        ]\n",
      "  [0.         1.         0.         0.3518571  0.        ]\n",
      "  [0.02553795 0.         0.         0.         0.6022312 ]\n",
      "  [0.         1.         0.28427136 0.         0.        ]\n",
      "  [1.         0.         0.41363516 0.         0.        ]\n",
      "  [0.         0.5275159  0.         0.5514315  0.84098434]\n",
      "  [0.         0.         0.         0.         0.28786644]]], Reward: [11.777418]\n",
      "Step 37: Action: [[[1.         0.6090529  0.         0.40828082 0.        ]\n",
      "  [0.16987965 0.77327985 0.         0.         0.        ]\n",
      "  [0.         0.         0.72477823 0.17890267 1.        ]\n",
      "  [1.         1.         0.         0.         0.8631033 ]\n",
      "  [1.         0.95975316 0.         0.         0.        ]\n",
      "  [0.         0.9786294  1.         0.09993829 0.27917394]\n",
      "  [1.         1.         0.         0.98947906 0.14080235]\n",
      "  [1.         1.         0.         0.30996186 0.38312912]\n",
      "  [0.         0.         0.7847438  0.         1.        ]\n",
      "  [1.         0.         0.         0.60527974 0.        ]]], Reward: [13.278037]\n",
      "Step 38: Action: [[[0.9362397  0.09483759 0.91439265 1.         0.        ]\n",
      "  [1.         1.         0.36379713 0.         0.        ]\n",
      "  [1.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.39260283]\n",
      "  [1.         0.         0.         0.         0.16918753]\n",
      "  [0.6199767  1.         0.5935358  0.8543633  0.05914246]\n",
      "  [1.         0.         1.         0.         0.        ]\n",
      "  [0.         0.5232806  0.14152798 0.         0.        ]\n",
      "  [0.         0.         0.3440814  0.         0.18989196]\n",
      "  [1.         0.         0.         1.         0.20194812]]], Reward: [9.946315]\n",
      "Step 39: Action: [[[0.14525554 0.54159856 0.61462307 0.62455565 0.        ]\n",
      "  [0.         0.21629632 1.         0.36330512 1.        ]\n",
      "  [1.         1.         0.4707616  1.         0.        ]\n",
      "  [0.96604735 1.         0.         0.         0.        ]\n",
      "  [0.         0.         0.946831   0.45538276 0.        ]\n",
      "  [0.20003656 0.67836833 0.37012422 0.         0.        ]\n",
      "  [0.6571073  0.18184122 1.         0.         1.        ]\n",
      "  [0.         0.         0.04709341 0.         0.        ]\n",
      "  [0.         0.         0.         0.3370038  0.03501225]\n",
      "  [0.21126695 0.         0.         0.         0.        ]]], Reward: [3.8139513]\n",
      "Step 40: Action: [[[0.8845609  0.         0.8907068  0.23488255 0.        ]\n",
      "  [0.         0.         0.16768223 1.         0.        ]\n",
      "  [0.         0.         0.         0.         0.7896997 ]\n",
      "  [0.48308885 0.         1.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.4883635  0.6944302 ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.8224497  1.         1.         0.        ]\n",
      "  [0.         0.32684535 0.         0.         0.        ]\n",
      "  [0.         0.69662726 1.         0.         0.3602588 ]]], Reward: [8.702388]\n",
      "Step 41: Action: [[[0.256255   0.988199   1.         0.00307314 0.        ]\n",
      "  [0.         1.         1.         0.         0.        ]\n",
      "  [1.         0.         1.         0.99255663 0.        ]\n",
      "  [0.         0.         0.         0.3542919  1.        ]\n",
      "  [0.5255804  1.         1.         0.3789726  1.        ]\n",
      "  [0.6431383  0.         0.73962414 0.         0.        ]\n",
      "  [0.         0.31443334 1.         0.         0.        ]\n",
      "  [0.         1.         0.         0.         0.        ]\n",
      "  [1.         0.7226543  0.         0.         0.        ]\n",
      "  [0.18590972 1.         1.         0.9407758  0.87341857]]], Reward: [8.882422]\n",
      "Step 42: Action: [[[0.         0.         0.44544357 0.         0.        ]\n",
      "  [0.62548256 0.         1.         0.         0.        ]\n",
      "  [0.         0.3967231  0.7643391  1.         0.        ]\n",
      "  [1.         0.         0.         0.548422   0.        ]\n",
      "  [0.64828414 0.5061759  0.61183244 0.         0.        ]\n",
      "  [0.         1.         0.         0.26504964 0.        ]\n",
      "  [0.7405908  1.         1.         1.         1.        ]\n",
      "  [0.         0.         0.06182408 1.         0.        ]\n",
      "  [0.         1.         0.         1.         0.51244235]\n",
      "  [0.         0.         0.         0.25439662 0.57883245]]], Reward: [12.444867]\n",
      "Step 43: Action: [[[0.30831885 1.         0.         1.         1.        ]\n",
      "  [0.22128253 0.41993594 1.         0.         0.        ]\n",
      "  [0.871983   0.97006196 0.36341843 0.         1.        ]\n",
      "  [1.         0.         0.         1.         0.21026145]\n",
      "  [1.         0.         1.         1.         0.5792355 ]\n",
      "  [0.37723985 0.03626533 0.         1.         0.6706997 ]\n",
      "  [0.16705568 0.         0.         0.         0.        ]\n",
      "  [0.         1.         0.         0.         0.84921515]\n",
      "  [0.         0.         0.         0.         0.38222364]\n",
      "  [0.         0.         0.9704553  0.         0.        ]]], Reward: [15.23285]\n",
      "Step 44: Action: [[[0.         1.         0.         0.24893753 0.        ]\n",
      "  [0.10029385 1.         0.         1.         0.86774117]\n",
      "  [1.         0.6484787  0.25280333 0.         1.        ]\n",
      "  [1.         1.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.4907933  0.3038484  1.         0.         1.        ]\n",
      "  [0.82028556 0.         1.         0.         1.        ]\n",
      "  [1.         0.         0.         0.4678     0.        ]\n",
      "  [0.83905524 0.         1.         0.         0.7890133 ]\n",
      "  [1.         1.         0.         0.         0.        ]]], Reward: [12.793687]\n",
      "Step 45: Action: [[[0.00573354 0.45818296 0.         0.         0.        ]\n",
      "  [0.91407084 1.         0.         0.         0.        ]\n",
      "  [0.         0.5059815  0.93275046 0.3272111  0.33438942]\n",
      "  [0.11365397 1.         0.         0.5755718  1.        ]\n",
      "  [0.         0.8099675  0.12221164 1.         0.        ]\n",
      "  [1.         0.         1.         0.         1.        ]\n",
      "  [1.         0.         0.06024881 1.         0.        ]\n",
      "  [0.         0.         1.         1.         1.        ]\n",
      "  [0.         0.         0.7236993  0.00894162 1.        ]\n",
      "  [1.         0.12030895 0.         0.         0.88206553]]], Reward: [7.595677]\n",
      "Step 46: Action: [[[0.         0.         0.04705634 0.         0.        ]\n",
      "  [0.         1.         0.         0.02241175 1.        ]\n",
      "  [0.         0.10126396 0.         0.15340549 1.        ]\n",
      "  [0.         0.         0.         0.93775624 1.        ]\n",
      "  [0.7154172  0.         0.38302878 0.         1.        ]\n",
      "  [1.         0.44152492 0.         0.         0.        ]\n",
      "  [0.         0.09311867 0.45858878 0.         0.33769953]\n",
      "  [1.         0.         0.7712268  1.         0.        ]\n",
      "  [0.         0.         0.4879745  0.8008592  0.        ]\n",
      "  [0.43134546 0.         0.         0.         0.        ]]], Reward: [7.430574]\n",
      "Step 47: Action: [[[0.5786487  1.         0.         1.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.02887691 0.12530787 0.         0.         0.5349715 ]\n",
      "  [1.         0.         0.3570075  0.         0.29474685]\n",
      "  [0.31293392 1.         1.         0.         1.        ]\n",
      "  [0.         1.         0.88140386 0.43353084 1.        ]\n",
      "  [0.         0.         1.         0.         0.3698481 ]\n",
      "  [0.47440326 0.         0.         0.         0.        ]\n",
      "  [1.         0.         0.01825993 0.         1.        ]\n",
      "  [0.         0.96482056 0.         0.23061907 0.        ]]], Reward: [9.120045]\n",
      "Step 48: Action: [[[0.23351803 0.91872823 0.71296996 0.         1.        ]\n",
      "  [1.         0.         0.5511166  0.         0.5948908 ]\n",
      "  [0.         0.26723644 0.         0.44938475 0.4240312 ]\n",
      "  [0.         1.         1.         0.         0.        ]\n",
      "  [0.02084231 0.         0.         1.         0.32084298]\n",
      "  [0.         0.65480983 0.         0.         0.5035703 ]\n",
      "  [1.         0.         1.         1.         0.7814628 ]\n",
      "  [0.         0.         0.         0.         0.12621747]\n",
      "  [0.98973006 0.         1.         1.         0.        ]\n",
      "  [0.3594612  0.         0.9005237  0.         0.        ]]], Reward: [11.951971]\n",
      "Step 49: Action: [[[0.5645117  0.         1.         0.96100634 0.        ]\n",
      "  [0.9596211  1.         0.8035169  1.         0.        ]\n",
      "  [0.10592489 0.         0.07435331 0.         0.67635554]\n",
      "  [0.         0.         0.8580841  0.53996205 0.        ]\n",
      "  [0.9386763  0.         1.         0.5717945  0.99958926]\n",
      "  [0.16121289 0.         0.14633738 1.         1.        ]\n",
      "  [0.         0.7963055  1.         0.         0.        ]\n",
      "  [0.83181167 1.         0.7587352  0.         0.51653886]\n",
      "  [0.         0.         0.01081568 1.         0.        ]\n",
      "  [0.         0.05757142 0.60591096 0.73046386 0.9123404 ]]], Reward: [15.52402]\n",
      "Step 50: Action: [[[0.         0.70107496 1.         0.         0.        ]\n",
      "  [0.         0.         0.69483733 0.40872774 1.        ]\n",
      "  [0.         0.8558792  0.         0.         1.        ]\n",
      "  [0.83536226 0.16097176 0.         1.         0.        ]\n",
      "  [1.         0.14895304 0.616618   0.         0.7912992 ]\n",
      "  [0.         0.         0.         0.         0.6525563 ]\n",
      "  [0.         0.         0.5668361  0.06456047 0.        ]\n",
      "  [0.85684335 0.         1.         0.863768   0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.7700654  0.         0.6915458  1.        ]]], Reward: [7.7764754]\n",
      "Step 51: Action: [[[1.         1.         0.         1.         0.        ]\n",
      "  [0.3836414  0.         0.         0.5521443  0.        ]\n",
      "  [0.05976929 0.09574664 0.         0.6750176  0.        ]\n",
      "  [0.         1.         0.         0.4180641  0.        ]\n",
      "  [0.72583014 1.         0.         0.         0.97503084]\n",
      "  [0.         1.         0.         0.65718347 0.42055073]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.614318   0.68878907 1.         0.         0.        ]\n",
      "  [0.         0.         0.94553053 0.         0.        ]\n",
      "  [0.16437046 0.         0.         0.         0.91417074]]], Reward: [7.303878]\n",
      "Step 52: Action: [[[0.         0.14584437 0.2026833  0.         0.9583353 ]\n",
      "  [0.         1.         1.         0.         1.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [1.         1.         0.45709106 0.         0.        ]\n",
      "  [0.6043629  0.16047488 1.         0.15818956 0.        ]\n",
      "  [0.         1.         0.         1.         0.94951856]\n",
      "  [0.         0.11322261 0.         0.         1.        ]\n",
      "  [0.         0.49579233 1.         0.         0.08616351]\n",
      "  [0.13161944 0.         0.         0.6007209  0.37588924]\n",
      "  [0.         0.         0.         0.         1.        ]]], Reward: [10.97897]\n",
      "Step 53: Action: [[[0.87988955 0.6736827  1.         0.         0.5505625 ]\n",
      "  [0.2599838  0.09747953 1.         0.40355417 0.        ]\n",
      "  [0.         0.38003117 0.17336592 0.4376306  0.        ]\n",
      "  [1.         0.14084658 0.         0.3914705  0.        ]\n",
      "  [0.         0.11500178 0.53340364 0.         0.610229  ]\n",
      "  [0.         0.8487504  0.4948488  0.8122332  0.        ]\n",
      "  [0.         0.         1.         0.2713133  0.        ]\n",
      "  [0.2893971  0.         0.         0.         0.        ]\n",
      "  [0.8248833  0.         0.         1.         0.31044298]\n",
      "  [0.6686775  0.         1.         0.77152365 0.        ]]], Reward: [7.517399]\n",
      "Step 54: Action: [[[0.         1.         0.         0.         0.30520362]\n",
      "  [0.         0.         0.34474108 0.         0.01170363]\n",
      "  [1.         0.         0.21912159 0.1763171  0.13377362]\n",
      "  [0.37481752 0.         1.         0.         0.        ]\n",
      "  [1.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.7136895  1.        ]\n",
      "  [0.6367532  1.         0.         0.02312236 1.        ]\n",
      "  [0.40122008 0.         0.17951827 0.         0.38861236]\n",
      "  [0.96026504 0.         0.74151814 1.         1.        ]\n",
      "  [0.         1.         1.         1.         0.        ]]], Reward: [9.913006]\n",
      "Step 55: Action: [[[0.         0.         0.         0.         0.4908348 ]\n",
      "  [1.         1.         0.2283211  0.51303    0.        ]\n",
      "  [0.         0.         1.         0.83818847 0.        ]\n",
      "  [0.9217594  0.84688085 1.         0.         0.39592594]\n",
      "  [0.         0.         0.         0.         0.794512  ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.09039932 0.19684905 0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         1.         0.         0.1231488  0.4604239 ]\n",
      "  [0.         0.         0.         1.         0.7855037 ]]], Reward: [1.589012]\n",
      "Step 56: Action: [[[0.         0.         0.         0.2538354  1.        ]\n",
      "  [0.         0.16965675 0.3561119  0.         0.        ]\n",
      "  [0.64639956 0.         0.         1.         0.35944492]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [1.         0.         0.02980747 0.         0.59180933]\n",
      "  [0.77419466 1.         0.63944906 0.52780914 0.        ]\n",
      "  [1.         0.86794615 0.         0.23309083 0.        ]\n",
      "  [0.         0.         0.         0.25458533 0.        ]\n",
      "  [0.6429135  0.27755454 0.         0.19203205 0.        ]\n",
      "  [0.00161923 0.94393843 0.28914618 0.90924263 0.        ]]], Reward: [10.260627]\n",
      "Step 57: Action: [[[0.         0.         0.52640045 0.7449541  0.        ]\n",
      "  [0.         0.49095672 0.         0.         0.9192695 ]\n",
      "  [0.         0.79084903 0.01744065 0.17564374 0.9723888 ]\n",
      "  [0.         0.35651964 0.         0.8747937  0.81066626]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.2542738  0.         0.         0.         0.        ]\n",
      "  [0.         1.         0.8472713  0.24651954 0.39671922]\n",
      "  [0.43152332 0.37471458 0.         0.20781407 0.        ]\n",
      "  [0.3108456  0.         0.         0.07538176 0.        ]\n",
      "  [0.37076834 1.         0.44863427 0.93823737 0.        ]]], Reward: [8.823139]\n",
      "Step 58: Action: [[[0.36325133 0.         0.9430018  1.         0.        ]\n",
      "  [0.06628402 0.         0.         1.         0.        ]\n",
      "  [0.12597784 0.         0.05797352 0.         0.        ]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.         0.         1.         0.7659958  1.        ]\n",
      "  [1.         0.9267707  0.         0.9073107  0.        ]\n",
      "  [1.         0.         0.15229285 0.         1.        ]\n",
      "  [0.03217436 0.         0.39634785 0.         0.        ]\n",
      "  [0.         0.         0.         1.         1.        ]\n",
      "  [1.         0.66104543 0.10385779 0.         0.        ]]], Reward: [9.297611]\n",
      "Step 59: Action: [[[0.0809534  0.         0.         0.         0.47124442]\n",
      "  [0.         0.7041583  1.         0.         1.        ]\n",
      "  [1.         0.96000916 0.4965755  1.         1.        ]\n",
      "  [0.11400641 0.         0.         0.         1.        ]\n",
      "  [0.41274455 0.06192978 0.         0.         0.        ]\n",
      "  [0.47831666 0.         0.         0.         0.        ]\n",
      "  [0.7565926  0.         0.2215898  1.         0.24078406]\n",
      "  [0.         1.         1.         0.         1.        ]\n",
      "  [0.         0.06783617 0.         0.43095744 0.6753136 ]\n",
      "  [0.         1.         0.         0.         0.        ]]], Reward: [4.291402]\n",
      "Step 60: Action: [[[0.         0.         0.89264    0.         0.18451495]\n",
      "  [0.5100514  0.         1.         0.         0.        ]\n",
      "  [0.         0.42968816 0.00394062 0.72255486 1.        ]\n",
      "  [0.956695   0.         0.         1.         0.        ]\n",
      "  [0.         0.27468127 0.         0.         0.        ]\n",
      "  [0.5976839  0.66884035 0.554458   0.         0.48266682]\n",
      "  [0.         0.40830594 0.         1.         0.        ]\n",
      "  [0.         1.         0.42399114 0.         0.        ]\n",
      "  [0.         0.24912748 0.         0.94398594 0.31090474]\n",
      "  [1.         0.87826276 1.         0.5284921  0.19105272]]], Reward: [8.289399]\n",
      "Step 61: Action: [[[0.         1.         1.         0.         0.19347495]\n",
      "  [0.16792735 0.23796074 0.         0.         0.63136625]\n",
      "  [0.         0.15521336 0.97464097 0.07698162 0.355313  ]\n",
      "  [0.         0.         0.18092631 0.         0.        ]\n",
      "  [0.         0.         0.         1.         0.        ]\n",
      "  [0.         0.11544608 0.7972727  1.         0.        ]\n",
      "  [1.         0.43360037 0.0380881  0.         0.        ]\n",
      "  [0.38443246 0.         0.         0.         0.9966872 ]\n",
      "  [0.         0.20769268 0.46175542 0.         0.        ]\n",
      "  [0.14835267 0.4613645  0.         0.5144253  0.21166375]]], Reward: [5.635286]\n",
      "Step 62: Action: [[[1.         0.5038919  1.         0.3795092  0.        ]\n",
      "  [0.         0.         0.03582203 0.67466724 0.        ]\n",
      "  [0.         0.         0.         0.50932556 0.22730115]\n",
      "  [0.9959344  0.         0.29923785 0.         0.        ]\n",
      "  [0.         0.03809091 0.         0.06217515 0.        ]\n",
      "  [0.26791352 0.9134557  0.         1.         0.        ]\n",
      "  [0.         0.         1.         0.         0.52079713]\n",
      "  [0.         1.         0.         0.60089254 0.        ]\n",
      "  [0.         1.         0.         0.         0.        ]\n",
      "  [0.07596476 0.         0.18390119 0.95588076 0.32981947]]], Reward: [4.7973304]\n",
      "Step 63: Action: [[[0.         0.44025767 1.         0.         0.01525121]\n",
      "  [0.80552477 0.         1.         0.11359558 1.        ]\n",
      "  [0.44397458 0.5665946  1.         0.92812735 0.        ]\n",
      "  [0.4858851  0.         0.28726998 0.         0.        ]\n",
      "  [0.         0.896045   0.         0.         0.        ]\n",
      "  [1.         0.         0.18004751 0.41947636 0.87101877]\n",
      "  [0.6331548  0.         0.         1.         0.        ]\n",
      "  [0.48439163 0.3423636  0.         0.44118196 0.6330398 ]\n",
      "  [0.7641851  1.         1.         1.         0.        ]\n",
      "  [0.         1.         1.         0.9961775  0.3949072 ]]], Reward: [16.531437]\n",
      "Step 64: Action: [[[0.         0.40652007 1.         0.         0.        ]\n",
      "  [0.49046126 1.         0.         0.6139084  0.23310426]\n",
      "  [1.         1.         0.         0.60024333 0.        ]\n",
      "  [0.49700373 0.53547704 0.         0.82125276 0.        ]\n",
      "  [0.         0.67308444 1.         0.         0.        ]\n",
      "  [0.03460772 0.         0.         0.7339056  0.        ]\n",
      "  [0.         0.         0.81454515 1.         0.        ]\n",
      "  [0.         0.         0.44745123 0.         1.        ]\n",
      "  [0.         0.77773416 0.         1.         0.4687951 ]\n",
      "  [0.         0.8910638  0.         0.         0.72368   ]]], Reward: [6.3679013]\n",
      "Step 65: Action: [[[0.43843693 0.8364755  1.         0.         0.82673615]\n",
      "  [1.         0.25494087 0.         0.8708577  0.        ]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.         0.00747807 1.         0.79943305 0.        ]\n",
      "  [1.         0.60502905 0.         1.         0.        ]\n",
      "  [1.         0.         1.         1.         0.591506  ]\n",
      "  [0.47724658 1.         0.         0.6527307  0.        ]\n",
      "  [0.         0.         0.         0.8055894  1.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [1.         0.         0.47586212 0.         0.        ]]], Reward: [9.108356]\n",
      "Step 66: Action: [[[1.         1.         0.         0.         0.        ]\n",
      "  [0.4094449  1.         0.22035468 0.         0.02831459]\n",
      "  [1.         0.         0.         0.         0.        ]\n",
      "  [0.8764596  1.         0.         0.7896391  1.        ]\n",
      "  [0.         0.0983156  0.         0.6608938  0.        ]\n",
      "  [0.         0.4459652  0.         0.41761765 0.19128525]\n",
      "  [0.         0.         1.         1.         0.31147337]\n",
      "  [0.62255573 0.47491473 0.4153346  0.01895262 0.        ]\n",
      "  [0.9194936  0.5674893  0.9093475  1.         0.        ]\n",
      "  [0.8097512  0.27056494 0.         0.         0.        ]]], Reward: [10.675183]\n",
      "Step 67: Action: [[[0.         0.         0.8423014  0.         1.        ]\n",
      "  [1.         1.         0.57284695 0.         0.24424395]\n",
      "  [0.         0.3899473  0.9808722  0.         0.87092566]\n",
      "  [0.         0.         1.         0.22965361 0.7005966 ]\n",
      "  [0.         0.60117203 0.7316099  0.         0.        ]\n",
      "  [1.         0.         0.02219152 0.         1.        ]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.06385481 0.1395056  0.        ]\n",
      "  [0.59468615 0.         0.00203136 0.         0.1313654 ]\n",
      "  [0.35594267 0.8061984  0.         0.         0.        ]]], Reward: [9.055217]\n",
      "Step 68: Action: [[[0.63660574 1.         0.4659589  0.         0.09992053]\n",
      "  [1.         0.         0.         0.16402495 1.        ]\n",
      "  [0.33400178 1.         0.8957167  1.         0.        ]\n",
      "  [0.3188854  0.         1.         0.70024055 0.        ]\n",
      "  [1.         0.         0.         0.         1.        ]\n",
      "  [1.         0.52536947 0.11667221 0.2712602  0.23825797]\n",
      "  [0.26386556 0.4700458  0.         0.         0.19267128]\n",
      "  [1.         0.         1.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.72308487]\n",
      "  [0.         0.12889616 0.9021505  1.         0.5829639 ]]], Reward: [7.573004]\n",
      "Step 69: Action: [[[0.         1.         0.5416797  0.         0.03557328]\n",
      "  [0.57494044 0.6349769  0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.66898865 1.         0.29924688 0.         0.        ]\n",
      "  [0.         0.         1.         0.44813186 0.1227334 ]\n",
      "  [0.         0.         0.         0.4639148  0.        ]\n",
      "  [1.         0.         0.         0.         0.29644793]\n",
      "  [0.         0.68796486 0.         1.         0.        ]\n",
      "  [0.35756597 0.4039717  0.         0.         1.        ]]], Reward: [5.4205747]\n",
      "Step 70: Action: [[[0.0000000e+00 0.0000000e+00 2.7936888e-01 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 6.6459566e-01 0.0000000e+00 8.5885301e-02 1.0000000e+00]\n",
      "  [6.4062691e-01 0.0000000e+00 1.2836850e-01 4.4736946e-01 9.3381423e-01]\n",
      "  [5.7937980e-01 1.0000000e+00 0.0000000e+00 7.7596921e-01 3.9987081e-01]\n",
      "  [0.0000000e+00 5.2016515e-01 1.4804178e-01 0.0000000e+00 2.7032077e-01]\n",
      "  [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.4617261e-01]\n",
      "  [1.0160416e-01 7.3736274e-01 1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      "  [3.2549515e-01 8.3381698e-02 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [3.7533301e-01 3.6499649e-04 9.8810279e-01 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.7390194e-01]]], Reward: [7.985478]\n",
      "Step 71: Action: [[[0.         1.         0.         0.11068339 0.        ]\n",
      "  [0.         0.         0.         0.03324158 1.        ]\n",
      "  [0.290653   0.20786202 0.         0.         0.07004673]\n",
      "  [0.         0.         1.         0.7211174  0.        ]\n",
      "  [0.         1.         0.7283395  0.         1.        ]\n",
      "  [1.         1.         0.03440006 0.9757019  0.        ]\n",
      "  [0.         0.4616274  0.         0.         1.        ]\n",
      "  [0.         1.         0.         0.31465763 0.84713745]\n",
      "  [1.         0.03190242 0.         0.         0.14478685]\n",
      "  [0.29348958 0.14337742 0.22670802 1.         0.        ]]], Reward: [5.9152803]\n",
      "Step 72: Action: [[[0.         0.11470459 0.04672936 0.4491628  0.        ]\n",
      "  [1.         0.8419672  0.         0.         0.        ]\n",
      "  [0.         0.256951   0.39067715 0.         0.        ]\n",
      "  [1.         1.         1.         0.         0.6686406 ]\n",
      "  [1.         0.         0.         0.01283196 1.        ]\n",
      "  [0.43803063 0.         0.57781535 0.94677633 0.5655628 ]\n",
      "  [1.         0.         0.         0.         1.        ]\n",
      "  [0.16228604 0.         0.5992657  0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.9122568  0.         0.         1.         0.        ]]], Reward: [7.597481]\n",
      "Step 73: Action: [[[0.9227359  0.28287625 0.         0.         1.        ]\n",
      "  [0.5627044  0.16093896 0.         0.         0.23939057]\n",
      "  [0.5872624  0.         1.         0.5730194  0.        ]\n",
      "  [0.40629482 1.         0.         1.         1.        ]\n",
      "  [0.         0.91667694 0.         0.         0.9827034 ]\n",
      "  [0.         0.12261212 0.         0.         0.11051295]\n",
      "  [0.         0.         1.         1.         1.        ]\n",
      "  [0.54418564 1.         0.         0.         0.        ]\n",
      "  [0.         1.         1.         0.5077048  0.8044615 ]\n",
      "  [1.         0.         0.         0.         0.35863835]]], Reward: [13.958871]\n",
      "Step 74: Action: [[[0.1910184  0.18002845 1.         0.         0.93196   ]\n",
      "  [0.7771496  0.3435793  0.         0.         0.        ]\n",
      "  [0.         0.9489584  0.3704628  0.746432   0.34477204]\n",
      "  [0.         0.         0.34478062 0.         0.        ]\n",
      "  [0.9034052  0.         0.         0.         0.02275959]\n",
      "  [0.06661668 1.         1.         1.         1.        ]\n",
      "  [0.9658407  0.         0.21974924 0.8217629  0.        ]\n",
      "  [0.2550052  0.         0.         0.         0.19836937]\n",
      "  [0.         1.         0.         0.         0.        ]\n",
      "  [1.         0.9840979  0.         0.28290874 0.6047813 ]]], Reward: [12.283876]\n",
      "Step 75: Action: [[[0.         1.         0.29930806 0.         0.        ]\n",
      "  [1.         1.         0.98451835 0.         0.        ]\n",
      "  [0.76371634 0.         0.92620784 0.         0.        ]\n",
      "  [1.         1.         0.         0.         0.09651189]\n",
      "  [0.4756762  0.04284104 0.         0.         0.        ]\n",
      "  [0.9686403  0.05624469 0.         0.         0.        ]\n",
      "  [0.13795406 0.63848954 0.13128646 1.         0.8824512 ]\n",
      "  [0.6445888  0.         0.64634657 0.84574115 0.        ]\n",
      "  [0.         1.         1.         0.         0.23272765]\n",
      "  [0.46492136 0.02735648 0.20876747 1.         0.02920063]]], Reward: [8.998053]\n",
      "Step 76: Action: [[[0.8225401  0.         0.6998696  0.         0.5128383 ]\n",
      "  [0.23588206 1.         0.         0.08577668 0.35296655]\n",
      "  [0.         0.         0.         0.         0.09860874]\n",
      "  [1.         0.20977777 0.         0.         0.14581306]\n",
      "  [0.         0.4245051  0.8715372  0.         0.        ]\n",
      "  [1.         0.         0.5834894  0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.37442198 0.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         1.        ]\n",
      "  [1.         0.07027864 0.         0.         1.        ]]], Reward: [7.1874013]\n",
      "Step 77: Action: [[[1.         0.7486952  1.         0.         1.        ]\n",
      "  [0.         0.         0.         0.11539981 0.        ]\n",
      "  [0.37412345 0.         1.         0.         0.6929562 ]\n",
      "  [0.28968686 0.         1.         0.         0.        ]\n",
      "  [0.         0.         0.         0.4235096  1.        ]\n",
      "  [0.5517459  0.36379293 0.         0.87205994 0.        ]\n",
      "  [0.2857111  0.01056834 1.         0.         0.        ]\n",
      "  [0.         0.4302546  0.         0.         0.        ]\n",
      "  [0.01287352 0.         0.90424156 0.         1.        ]\n",
      "  [0.7781621  0.         0.03933615 0.         0.        ]]], Reward: [4.9301763]\n",
      "Step 78: Action: [[[0.         0.03886759 0.         0.66021967 0.63909155]\n",
      "  [0.88375    0.         0.         1.         0.69884145]\n",
      "  [0.         0.         0.2024944  0.         0.50219256]\n",
      "  [1.         1.         0.         0.         1.        ]\n",
      "  [0.         0.97734827 0.         0.3414231  1.        ]\n",
      "  [0.         0.         0.         0.01910438 0.36893266]\n",
      "  [0.         0.         1.         1.         0.        ]\n",
      "  [0.         0.69539016 0.5258079  0.         0.8623663 ]\n",
      "  [0.         0.943854   0.         0.         0.98522335]\n",
      "  [0.         0.43677065 0.17813325 0.         0.        ]]], Reward: [8.193079]\n",
      "Step 79: Action: [[[0.         1.         0.84690523 0.         0.7145281 ]\n",
      "  [0.         0.         0.         1.         0.43313307]\n",
      "  [0.         0.         1.         0.28527135 0.34364054]\n",
      "  [0.         0.         0.         1.         0.        ]\n",
      "  [0.32232684 0.03645542 0.         0.         0.        ]\n",
      "  [0.37515104 0.         0.7689518  0.11115922 1.        ]\n",
      "  [0.         0.         0.         0.0072862  0.        ]\n",
      "  [0.96060914 1.         0.7078685  1.         0.54763746]\n",
      "  [1.         0.24105427 1.         0.95954573 0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]]], Reward: [9.66788]\n",
      "Step 80: Action: [[[0.         0.         0.24912053 0.         0.5089152 ]\n",
      "  [0.47044358 0.         1.         0.         0.29296887]\n",
      "  [0.35030764 1.         0.         0.         1.        ]\n",
      "  [0.3917611  1.         0.         0.         0.43965015]\n",
      "  [0.         0.19391164 0.         0.84435225 0.38009608]\n",
      "  [0.         0.         0.         0.         0.87755835]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.16990478 0.         0.        ]\n",
      "  [1.         0.         0.         0.91339254 0.        ]\n",
      "  [0.         0.         1.         1.         1.        ]]], Reward: [7.2541]\n",
      "Step 81: Action: [[[0.4204574  0.7753482  1.         0.         0.        ]\n",
      "  [1.         0.8190051  0.7797496  0.2689989  1.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.81831044 0.01383536 0.         0.52735144 0.        ]\n",
      "  [0.9053865  0.         0.07620644 0.         0.        ]\n",
      "  [1.         0.36898905 0.         1.         1.        ]\n",
      "  [0.         0.         0.         0.6510237  0.        ]\n",
      "  [1.         0.13074853 0.59280944 0.         0.        ]\n",
      "  [0.         0.         0.         0.04091442 1.        ]\n",
      "  [0.52844554 0.45452243 0.84651315 0.60363454 1.        ]]], Reward: [9.136669]\n",
      "Step 82: Action: [[[0.         1.         1.         0.         0.08674662]\n",
      "  [0.09753222 0.         0.23992822 0.         0.29075906]\n",
      "  [0.12532127 0.97576225 0.         0.         0.8078846 ]\n",
      "  [0.03937166 0.78587633 0.7465492  0.35517412 0.        ]\n",
      "  [1.         0.3139713  0.         0.5369133  0.        ]\n",
      "  [0.         0.         0.9307343  0.         0.        ]\n",
      "  [0.89912546 1.         0.         0.         0.        ]\n",
      "  [1.         1.         1.         0.         0.02557499]\n",
      "  [0.         1.         1.         0.70162916 0.        ]\n",
      "  [0.         0.8804485  0.         0.7048559  0.        ]]], Reward: [8.808803]\n",
      "Step 83: Action: [[[0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         1.         0.         0.5847611 ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.02592623 0.         1.         0.         0.        ]\n",
      "  [1.         0.         0.         0.13739607 0.02495223]\n",
      "  [1.         0.         0.27219304 0.         0.        ]\n",
      "  [1.         0.3195577  0.         0.         0.05444182]\n",
      "  [0.4525729  0.         0.         0.         0.1670842 ]\n",
      "  [0.79988    1.         0.         0.         0.        ]]], Reward: [4.907362]\n",
      "Step 84: Action: [[[0.         0.02564344 0.         0.         0.        ]\n",
      "  [0.33487168 0.         0.         0.51267666 0.        ]\n",
      "  [0.759313   1.         0.         0.         0.        ]\n",
      "  [0.6597817  0.         0.         0.75990146 1.        ]\n",
      "  [0.         0.23312691 0.19914071 0.19228876 0.        ]\n",
      "  [0.4284774  1.         0.         0.         0.64015394]\n",
      "  [0.9345221  1.         0.         0.8631437  0.48577055]\n",
      "  [0.         0.         0.         0.7857462  0.        ]\n",
      "  [0.         0.         0.         0.         0.13875131]\n",
      "  [0.30048257 0.         0.         0.         0.        ]]], Reward: [9.423942]\n",
      "Step 85: Action: [[[0.19709325 0.5268011  0.7003185  0.21933326 0.        ]\n",
      "  [0.39847553 0.         0.03678779 0.85050184 1.        ]\n",
      "  [0.         0.         0.43063694 0.         0.99047047]\n",
      "  [0.         0.7080517  1.         0.         0.        ]\n",
      "  [0.         0.         0.4346917  0.51151276 0.        ]\n",
      "  [0.         0.         0.9612058  0.         0.        ]\n",
      "  [0.         0.16351995 0.23580691 0.         0.        ]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         0.5032475  0.23475935]]], Reward: [7.7878017]\n",
      "Step 86: Action: [[[0.         1.         1.         0.8379412  0.59583384]\n",
      "  [0.         0.58996916 0.62416    0.         1.        ]\n",
      "  [0.8611132  0.         0.         0.46082914 0.        ]\n",
      "  [0.         0.         0.5985165  1.         0.        ]\n",
      "  [0.         1.         0.50848734 0.77983147 0.        ]\n",
      "  [0.         0.07841477 0.         0.         1.        ]\n",
      "  [0.         1.         0.         0.         0.        ]\n",
      "  [0.         0.         0.44502386 0.         1.        ]\n",
      "  [0.4971782  0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.         1.         0.        ]]], Reward: [10.216457]\n",
      "Step 87: Action: [[[0.         0.         1.         1.         0.5601933 ]\n",
      "  [0.98756975 0.         0.         0.         1.        ]\n",
      "  [0.         0.14728658 0.7148723  0.09241495 0.10664655]\n",
      "  [1.         0.31296775 0.12383451 0.89578193 0.5506106 ]\n",
      "  [0.46553442 0.         1.         1.         0.10688478]\n",
      "  [0.58589166 0.1477393  0.         0.67349476 0.        ]\n",
      "  [0.         0.93786705 1.         0.43178466 0.        ]\n",
      "  [0.         0.         1.         1.         0.07494253]\n",
      "  [0.         0.         0.8753685  0.8739294  0.22581092]\n",
      "  [0.         0.         0.         0.         1.        ]]], Reward: [10.19142]\n",
      "Step 88: Action: [[[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.5808159e-01]\n",
      "  [1.0000000e+00 0.0000000e+00 8.2101747e-02 0.0000000e+00 0.0000000e+00]\n",
      "  [6.8875098e-01 1.0000000e+00 9.4949090e-01 5.6094974e-03 6.2690824e-01]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.7046098e-01 0.0000000e+00]\n",
      "  [9.2048031e-01 3.3731616e-01 0.0000000e+00 1.0000000e+00 8.7210423e-01]\n",
      "  [9.1566151e-01 2.2135352e-01 0.0000000e+00 0.0000000e+00 7.6867139e-01]\n",
      "  [0.0000000e+00 0.0000000e+00 3.5864237e-01 6.6522872e-01 8.8521048e-02]\n",
      "  [0.0000000e+00 8.3499491e-01 1.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [4.4530460e-01 1.4553131e-01 7.6869720e-01 8.7014616e-01 0.0000000e+00]\n",
      "  [1.0000000e+00 1.0000000e+00 1.9819009e-01 1.0000000e+00 5.2602030e-04]]], Reward: [11.76773]\n",
      "Step 89: Action: [[[0.2696045  0.         0.73347634 0.         0.        ]\n",
      "  [0.         1.         1.         0.         1.        ]\n",
      "  [0.         1.         0.83360237 1.         0.22698864]\n",
      "  [0.         1.         0.         0.         0.        ]\n",
      "  [0.         0.         0.0203766  0.         0.36216354]\n",
      "  [0.6200993  0.17398208 1.         0.         0.        ]\n",
      "  [0.5379079  0.         0.         0.         0.26574755]\n",
      "  [1.         1.         0.15024303 0.8248795  0.5030095 ]\n",
      "  [0.63048315 0.9832854  0.08225703 0.3399965  0.25087166]\n",
      "  [0.9160269  0.         0.         0.72137207 0.        ]]], Reward: [10.779041]\n",
      "Step 90: Action: [[[1.         1.         0.         0.         0.92393017]\n",
      "  [0.         0.86327976 1.         0.3771765  1.        ]\n",
      "  [0.         0.7268216  0.03740629 0.         0.44354415]\n",
      "  [1.         0.         0.38617152 0.6040152  0.        ]\n",
      "  [1.         0.00761236 1.         0.         0.        ]\n",
      "  [0.29558814 1.         0.40434217 0.26277772 0.        ]\n",
      "  [0.         0.7958772  0.         0.         0.        ]\n",
      "  [0.5791936  0.         0.         0.         0.67006147]\n",
      "  [1.         0.24325171 0.         0.         0.        ]\n",
      "  [0.         0.91450715 0.14955924 1.         0.        ]]], Reward: [9.022124]\n",
      "Step 91: Action: [[[0.         0.759645   1.         0.07161376 1.        ]\n",
      "  [1.         0.78098845 0.         1.         0.        ]\n",
      "  [0.         0.31959835 1.         0.         1.        ]\n",
      "  [0.         0.         0.7710606  1.         0.9648919 ]\n",
      "  [0.         0.5621099  0.         0.25363365 0.        ]\n",
      "  [0.44124085 0.         0.         1.         0.        ]\n",
      "  [0.45783475 0.         0.24944994 0.1734917  0.        ]\n",
      "  [1.         0.         0.08271961 0.         0.56111807]\n",
      "  [0.         0.04025917 0.06121732 1.         1.        ]\n",
      "  [1.         0.20498104 1.         0.         0.09089926]]], Reward: [9.526205]\n",
      "Step 92: Action: [[[1.         0.         0.         0.64893353 1.        ]\n",
      "  [1.         0.         0.         1.         0.        ]\n",
      "  [0.         0.05035408 0.         0.3341563  1.        ]\n",
      "  [0.81641036 0.         1.         0.         0.        ]\n",
      "  [0.         0.1628358  0.6370539  0.39503238 0.        ]\n",
      "  [0.7504432  0.         0.00137409 0.10991742 0.        ]\n",
      "  [0.5015116  1.         0.30457357 0.         1.        ]\n",
      "  [0.         0.         0.9912146  0.         0.        ]\n",
      "  [0.         1.         1.         0.18572032 0.09180265]\n",
      "  [0.         0.         1.         1.         0.        ]]], Reward: [6.821943]\n",
      "Step 93: Action: [[[0.27251473 0.39432997 0.73508376 0.         1.        ]\n",
      "  [0.5926461  1.         0.         0.         0.        ]\n",
      "  [0.         0.01390417 0.8023735  0.06539644 0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [1.         0.         0.         0.7844062  0.        ]\n",
      "  [0.         0.28601286 0.         0.         0.        ]\n",
      "  [1.         0.         1.         0.02847253 0.8152055 ]\n",
      "  [0.85380244 0.07468395 0.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.3617565  0.05262452 1.         0.         0.        ]]], Reward: [3.130907]\n",
      "Step 94: Action: [[[4.4908690e-01 2.5848025e-01 0.0000000e+00 0.0000000e+00 6.9310272e-01]\n",
      "  [0.0000000e+00 0.0000000e+00 1.3353398e-01 0.0000000e+00 1.6471274e-01]\n",
      "  [0.0000000e+00 1.0000000e+00 0.0000000e+00 4.6705276e-01 0.0000000e+00]\n",
      "  [6.8719685e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.8550518e-01]\n",
      "  [1.0000000e+00 1.4397024e-01 0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      "  [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00]\n",
      "  [4.4709817e-04 1.3283101e-01 2.5045073e-02 1.0000000e+00 0.0000000e+00]\n",
      "  [0.0000000e+00 0.0000000e+00 1.0000000e+00 5.9732264e-01 1.9958304e-01]]], Reward: [3.9888368]\n",
      "Step 95: Action: [[[0.08179148 0.         0.11579021 1.         0.30339152]\n",
      "  [0.50507    1.         0.         0.1691136  0.        ]\n",
      "  [1.         0.         1.         0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.4303478 ]\n",
      "  [0.         0.         1.         0.         0.        ]\n",
      "  [0.         0.48488843 1.         0.         1.        ]\n",
      "  [0.         0.         0.08732089 1.         0.01607747]\n",
      "  [0.         0.         1.         0.         1.        ]\n",
      "  [0.         0.         0.         0.92777073 0.00281829]\n",
      "  [0.         0.         0.12044442 0.         0.        ]]], Reward: [4.292128]\n",
      "Step 96: Action: [[[0.1202843  0.         0.         1.         0.        ]\n",
      "  [0.99878716 0.         0.64556885 0.         0.        ]\n",
      "  [0.         0.38944075 0.         0.         0.3291577 ]\n",
      "  [1.         0.         0.         0.         0.77703357]\n",
      "  [0.41760117 1.         0.         1.         0.        ]\n",
      "  [0.12952459 1.         0.         1.         0.35541052]\n",
      "  [0.95565    0.8884662  0.         0.21437539 0.29629374]\n",
      "  [0.         0.2549398  0.         1.         0.        ]\n",
      "  [0.01945299 0.         0.51932776 0.22738251 1.        ]\n",
      "  [0.04070887 0.         0.         0.8331775  1.        ]]], Reward: [14.30502]\n",
      "Step 97: Action: [[[0.31259125 0.3254761  0.         0.         0.16999769]\n",
      "  [0.         1.         0.         0.         0.        ]\n",
      "  [0.         0.         0.16415256 1.         0.        ]\n",
      "  [0.4901643  1.         1.         0.         0.        ]\n",
      "  [1.         0.         0.15085627 0.7466772  0.        ]\n",
      "  [1.         0.         0.43581706 0.         0.        ]\n",
      "  [0.         0.         0.         0.         0.        ]\n",
      "  [0.         0.3702726  0.         0.         0.2646807 ]\n",
      "  [0.         1.         0.         0.99570495 0.        ]\n",
      "  [1.         0.         0.2552787  0.         0.        ]]], Reward: [4.0037103]\n",
      "Step 98: Action: [[[0.         0.         1.         1.         0.1822225 ]\n",
      "  [0.48070133 0.         0.7820348  0.         0.        ]\n",
      "  [0.         0.23459151 0.         0.977791   0.9443972 ]\n",
      "  [0.         0.73153096 0.         0.         1.        ]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.         0.         0.19275042 1.         0.        ]\n",
      "  [0.33653346 0.08303773 0.         1.         1.        ]\n",
      "  [0.         0.         1.         0.37553793 0.        ]\n",
      "  [0.37108153 0.50349706 0.         1.         0.79874676]\n",
      "  [0.01881783 0.02422112 0.         0.         1.        ]]], Reward: [12.876371]\n",
      "Step 99: Action: [[[0.         0.20854935 0.         0.         0.        ]\n",
      "  [0.47827512 1.         0.83937377 0.         0.28464514]\n",
      "  [0.         0.         0.         0.         1.        ]\n",
      "  [0.8092901  0.04984272 0.55595756 0.12142591 0.        ]\n",
      "  [1.         1.         0.40420642 0.         0.        ]\n",
      "  [1.         0.         1.         0.89500254 0.        ]\n",
      "  [0.         1.         0.7358739  0.48876256 0.        ]\n",
      "  [0.         1.         0.         0.7379378  0.        ]\n",
      "  [0.         0.         1.         0.29810417 0.02637529]\n",
      "  [0.         0.         0.         0.         0.        ]]], Reward: [8.345131]\n",
      "Step 100: Action: [[[0.         0.         0.         1.         1.        ]\n",
      "  [0.5772378  0.         1.         0.         0.37173834]\n",
      "  [0.         0.         0.2432743  0.         0.        ]\n",
      "  [0.6248151  1.         0.         0.69709396 0.41963127]\n",
      "  [0.         0.         0.         1.         0.        ]\n",
      "  [0.         0.46538773 0.         0.         0.14203812]\n",
      "  [1.         0.         0.6287278  1.         0.        ]\n",
      "  [1.         1.         1.         0.25560763 0.189192  ]\n",
      "  [0.         0.3627559  0.5379087  0.         0.54122806]\n",
      "  [0.31757528 0.         0.64641035 1.         0.        ]]], Reward: [5.463207]\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the environment\n",
    "env = CellularEnv(num_users=10, num_rb=5)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "\n",
    "# Create the PPO agent\n",
    "ppo_agent = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "\n",
    "# Train the agent\n",
    "ppo_agent.learn(total_timesteps=10000)\n",
    "\n",
    "# Save the agent\n",
    "ppo_agent.save(\"ppo_cellular_env\")\n",
    "\n",
    "# Test the trained agent\n",
    "obs = env.reset()\n",
    "for i in range(100):\n",
    "    action, _states = ppo_agent.predict(obs)\n",
    "    obs, reward, done, info = env.step(action)\n",
    "    print(f\"Step {i+1}: Action: {action}, Reward: {reward}\")\n",
    "    if done:\n",
    "        obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834bff2-4b7d-4cd2-8b37-376b55b1da0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
